\chapter{Introduction}

% object, area, goal
An important piece of work in the information systems field by Antoni Olive \cite{CMofIS} defines the term \textit{conceptual modeling} as the activity of describing and structuring the general knowledge a particular information system needs to know.
The main objective of conceptual modeling is to obtain that description, which is called a \textit{conceptual schema}.
Conceptual modeling is an important part of requirements engineering, the first and most important phase in the development of an information system.
However, any information system will invariably undergo modification, either due to the demands of its users or as a result of a change in the nature of the information itself or for other reasons.
Therefore, one of the most important properties of information systems is evolvability.

\n

%It is often the case that a description of a conceptual schema needs to be represented in a system. 
%However, not in the form of source code, but contained in the source code.
An ability to access and process the information about a conceptual schema programmatically at runtime is widely used by various technologies for automation of otherwise complex and error-prone software engineering tasks.
For example, Object-Relational Mapping (ORM)\footnote{Object-Relational Mapping is a technique used to interact with a database through an interface in object-oriented paradigm.} technologies automate mapping between two representations of a conceptual schema: expressed in OOP terms as classes and expressed in terms of a relational database.
This information is a structured representation of a conceptual schema, which we shall refer to as \textit{meta-model}.
Although accessible at runtime, such meta-models also need to be made available to software engineers at design time.
The information provided by meta-model is called \textit{metadata}.
Since this meta-level information is also a part of a system it is desirable for it to be evolvable as well.
Moreover, due to the fact that a meta-model reflects the structure of a conceptual schema, it must be consistent with it.
Ideally, a meta-model would always be automatically updated to match the structure of a conceptual schema.

\n

The aim of this research is to develop a technology for compile time semantic analysis that would capture the description of conceptual models in a form of metadata directly represented in the source code. 
We outline the following objectives:
\begin{enumerate}
    \item Improve \textit{domain modeling} efficiency and provide advanced \textit{domain discoverability} features at design time.
    \item Improve system reliability and ensure correctness of references to domain models at compile time.
    \item Improve system evolvability.
\end{enumerate}

The key result of this research is the developed technology itself -- an approach to achieve the stated objectives.

\section{Domain modeling}
Any software system aims to address a specific problem.
The area surrounding this problem is known as the problem domain. \textit{Domain modeling} is a form of conceptual modeling commonly used in software engineering.
Its aim is to construct a \textit{domain model} -- a structured representation of the problem domain with a description of core concepts and their relationships.
We define \textit{domain discoverability} as the ability to \textit{discover} the domain model, that is, to inspect the conceptual schema of the domain.
We later show that domain discoverability can be limited by the programming language used to write the software.

\n

% rewrite in terms of conceptual modeling of information systems + a constant need for change
Efficient software engineering requires a certain kind of knowledge to be present in the mind of a software engineer. 
Peter Naur \cite{naur} conveyed an insightful idea of Theory Building View of programming, stating that a program is a shared mental construct that lives in the minds of the people who work on it.
Therefore, the programmer possessing the theory is able to respond constructively to any demand for a modification of the program.
The same can be said about domain modeling where the general knowledge of the domain needs to be present at all times in order to develop correct models.
However, that might prove to be a difficult task for a domain of significant size, requiring the software engineers to frequently brush up their knowledge of the target domain through the use of a secondary source of information, such as documentation or source code of the software.
In order to tackle this difficulty many supporting tools have been developed. For example, modern IDEs\footnote{Integrated Development Environment (IDE) is software that combines common developer tools into a single graphical user interface.} come with a handful of advanced features, such as code auto-completion, which is a practical way of enhancing domain discoverability.

\n

Brooks \cite{brooks} defines two kinds of complexity involved in the process of software construction: essential and accidental.
Essential complexity stems from the inherent properties of software, such as the size of software systems, conformity to other interfaces, changeability and invisibility (inability to be visualized).
Accidental complexity is manifested in any activity that engages in representation of conceputal software structures in programming languages and mapping of those structures onto machine languages within space and speed constraints.
Among past breakthroughs in solving accidental difficulties are: high-level programming languages, time-sharing systems and unified programming environments.
Following Brooks’s excerpt on time-sharing which he views as an attack on a specific accidental difficulty -- interruption of consciousness due to a need to call for compilation and execution, which might result in the decay of grasp of all that is going on in a complex system -- our main hypothesis is that the lack of programming language-level metamodeling facilities with advanced design-time domain discoverability features is the same kind of difficulty with negative effects of similar nature.

\section{System reliability}
% informal reasoning, cite Out of the Tar Pit
Reliability of a system is its ability to perform a given task in an expected way without causing errors.
In order to build reliable systems it is important to understand those systems.
Moseley \& Marks \cite{moseley} identified two widely-used approches to understanding systems: \textit{testing} and \textit{informal reasoning}; with an emphasis on the importance of the latter.
Informal reasoning is an attempt to understand the system by examining it from the inside.
Its importance was explained by Moseley \& Marks by the fact that improvements in informal reasoning lead to \textit{less errors being created}, as opposed to improvements in testing that lead only to \textit{more errors being detected}.
One of the desirable properties of testing is high code coverage, which is a measure of the amount of source code of a program that was executed, hence covered, during testing.
However, for systems of significant size, characterized by large code volume with complex structure, testing is usually a time consuming process.
No guarantees can be given that a failing test will not occur at the very end of the whole process.
Because of this, understanding systems through testing is also more time-consuming.
Therefore, it is preferable to focus on ways of improving informal reasoning.

\n

When we examine a system from the inside we do it at design time, that is, during the phase of system construction.
For example, reasoning about the source code of a system's component is an activity carried out at design time.
Modern IDEs blur the line between design time and compile time, seemlessly integrating the compilation process into design time in order to increase developer productivity.
This allows software engineers to benefit from messages signaled by a compiler, making a great contribution to improvements in informal reasoning.
Therefore, delegating as much system validation as possible to a compiler will result into more reliable systems.

\section{System evolvability}
% link this to "informal reasoning" (out of the tar pit)
All systems are prone to change, especially the successful ones.
This is due to the fact that software that is found to be useful is often pushed to its limits by its users who invent new uses for it.
Change management thus plays an essential role in the lifecycle of a software system.
Whenever a change is introduced to the domain model, all parts of a system that interact with the changed component must be verified and modified if necessary.
While the verification is usually covered by automated tests, the modification of related components has to be carried out by a software engineer.
In order to ensure that the latest change is adopted correctly a software engineer must know the exact locations of those components in the source code.
Once again, this can be a difficult task when working with a large system and that is why the role of a compiler is critical, for it can inform the software engineer of those places in the source code.

\n

The underlying assumption is that software is being developed in a compile time safe manner.
However, given the general purpose nature of modern programming languages, this assumption is not always true.
There is a lack of a language-level abstraction that could be used as domain model metadata, that carries type information, to reference the conceptual model.
This limitation forces software engineers to use textual string representations instead that are "hard-coded" into the program.
This is known to be unreliable because a compiler can't validate the contents of a string, thus a program deemed valid by a compiler might contain incorrect metadata that results in a runtime error.
Although, were the metadata represented in the form of a meta-model instead, all rules of compile time validation would be applicable to it.
Moreover, any modification to the domain model would be reflected in the meta-model.
Therefore, it would be possible to efficiently track the related components in need of modification at design time due to messages signaled by a compiler.

\n

To illustrate a possible case where a meta-model might be required we provide the following example.
A simple example of a situation where domain model metadata is required is illustrated in the following code snippet that constructs a query to a database:

\begin{listing}[H]
    \begin{minted}{java}
    class Customer {
        private String name;
        private int age;
    }
    \end{minted}
    \caption{A java class for a \texttt{Customer} concept.}
    \label{lst:intro-customer}
\end{listing}


\begin{listing}[H]
    \begin{minted}{java}
    String query = "SELECT name FROM customers WHERE age >= 21;";
    \end{minted}
    \caption{SQL query with hard-coded metadata that fetches the names of all customers of age over 21.}
    \label{lst:intro-sql-raw}
\end{listing}

The problem with this code is that it uses "hard-coded" metadata.
A compiler can't tell whether \texttt{name} is a part of the \texttt{Customer} concept.
It also has no way of verifying whether \texttt{customers} is a valid database table.
As a result, this code is unreliable and difficult to maintain.
It is easy to imagine that some time in the future the conceptual schema might change leading to the \texttt{Customer} concept no longer having the attribute \texttt{name}, but \texttt{fullName} instead.
Consequently, each such occurence of hard-coded metadata must be manually located throughout the whole system.

\n

It is true that using raw strings to construct SQL queries is a bad practice and alternative approaches have been developed, such as ORM frameworks.
However, the core issue still remains unsolved, as demonstrated by the following example.

\begin{listing}[H]
    \begin{minted}{java}
    QueryModel<Customer> query = select(Customer.class).where()
        .prop("age").gt().val(21)
        .yield().prop("name")
        .model();
    \end{minted}
    \caption{SQL query from \ref{lst:intro-sql-raw} expressed using an ORM framework.}
    \label{lst:intro-eql}
\end{listing}

The \texttt{"age"} and \texttt{"name"} strings still must be used to refer to \texttt{Customer} attributes.

\smallskip

Now, consider an approach utilizing a meta-model:

\begin{listing}[H]
    \begin{minted}{java}
    QueryModel<Customer> query = select(Customer.class).where()
        .prop(Customer_.age).gt().val(21)
        .yield().prop(Customer_.name)
        .model();
    \end{minted}
    \caption{SQL query from \ref{lst:intro-eql} using a meta-model.}
    \label{lst:intro-sql-meta}
\end{listing}

Here \texttt{Customer\_} is a meta-model class. 
It guarantees that the database query is constructed in a compile time safe manner, since a change to the domain model is immediately reflected in the meta-model.
In case a breaking change took place, an appropriate compilation error would follow.

\section{Technical approach}
Taking into account the widespread adoption and use of object-oriented programming in domain-driven design, we focus on the Java programming language in particular.
Since Java language specification does not support class meta-models, we provide our own implementation of a meta-model generation mechanism. 
The implementation is based on a feature of Java -- annotations, supplemented by annotation processing -- an ability to process annotations at compile time.

\n

The implementation we provide is designed with a particular software development technology in mind – Trident Genesis (TG). The choice was made to integrate the implementation with the surrounding framework in order to make the development process manageable in terms of time, and, given its experimental nature, it was preferable to narrow down the scope of application, while making it practical. This choice does not invalidate a general nature of the research.

\n
Trident Genesis (TG) is a software development technology, which has been developed by Fielden Management Services Pty. Ltd (Australia).

\n

TG fits well into the definition of domain-driven development, as it shares the common language of domain modeling, speaking in terms of domain entities and their relationships.

\section {Qualitative research}
In order to assess the extent to which the stated objectives were achieved the experimental component of this work is carried out by employing an approach of qualitative research.
The applictation of qualitative reserach to the field of software engineering is discussed by Hazzan \& Dubinsky \cite{hazzan}.

\n

The conducted experiments involve a focus group of select software engineers from the industry, who are practicing domain-driven development as their main software design approach, making them ideal candidates to test our main hypotheses.
We use a questionnaire as a main data gathering tool.

\n

Richard Pawson \cite{pawson}'s work is one great example of an application of qualitative research methods to the field of software engineering.

\section{Structure}

This work is structured in the following way: 

\n

\noindent Chapter 2 goes into depth about key concepts and provides the necessary background for the rest of the paper.

\n

\noindent Chapter 3 discusses related work, comparing the approaches employed. Each approach is examined in great detail with its strengths and limitations outlined.

\n

\noindent Chapter 4 provides a detailed description of the implementation. It discusses the developed algorithm step-by-step with attached illustrations and examples.

\n

\noindent Chapter 5 describes the experiment. It includes a display of the questionnaire contents and answers of the participants.

\n

\noindent Chapter 6 discusses future work that encompasses a general framework independent approach and draws on shortcomings of the implementation.
