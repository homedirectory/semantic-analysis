\chapter{Experiment}

Evaluation of the developed technology was conducted in the form of an experiment.
The motivation behind this choice was the desire to assess the extent to which all stated objectives were reached.
Although, the intuitive choice was to employ an approach of automated software testing, not all objectives could be effectively assessed in that manner.
Domain discoverability, in particular, is better suited to evalutaion by opinion, because of its subjective nature. Also, given rather uncommon software development technique of code generation, as well as the intricate dependencies between the generated and source code, it was challenging to use automated tests for assessment of the other two objectives, namely, model consistency and evolvability. Therefore we use the experiment as a single source of evaluation.

\n

Naturally, given the tight coupling to Trident Genesis, the experiment's audience was comprised of 7 software engineers working on several projects built with TG at their core.
The experiment had been conducted over a period of one week, at the end of which every team member was asked to fill out a questionnaire.
Each individual was asked to agree/disagree with a handful of statements and optionally provide additional comments.

\n

Despite the fact that the actual duration was shorter than originally planned, most answers convey enough information with only a few where several respondents share the opinion that more time is required. 
What follows is a display of responses, accompanied by several selected comments that contributed valuable insight.

\section{Discoverability of the domain model}

\mychart{5}{2}{0}{0}{0}{Question 1: Domain discoverability}{The information provided by meta-models in the form of javadoc combined with the IDEâ€™s code auto-completion feature made domain discoverability more efficient.}

\mychart{5}{2}{0}{0}{0}{Question 2: Domain discoverability}{When attempting to refer to a property of an entity using a meta-model, there was no need for context switching, i.e., opening an entity class and looking for the property definition.}

\mychart{0}{2}{3}{1}{1}{Question 3: Domain discoverability}{The generated meta-models could contain more information about their underlying entities.}

\section{Reliability}

\mychart{4}{3}{0}{0}{0}{Question 4: Reliability}{Usage of the generated meta-models proved to be a reliable way of referencing properties of an entity, i.e., there were no occurrences of runtime errors.}

\section{Evolvability}

\mychart{4}{2}{1}{0}{0}{Question 5: Evolvability}{Evolvability of a system against modifications to the conceptual model increased due to compile-time validation in places where the generated meta-models were referenced.}

\section{Performance}

\mychart{5}{2}{0}{0}{0}{Question 6: Performance}{Impact of the meta-model generation process on performance of the IDE during compilation has been insignificant to the development process.}

\section{Correctness of the generation mechanism}
\mychart{4}{2}{1}{0}{0}{Question 7: Correctness}{The meta-model generation mechanism was always correctly generating meta-models for newly added entities.}

\mychart{4}{2}{1}{0}{0}{Question 8: Correctness}{The meta-model generation mechanism was acting correctly in response to the renaming / deletion of an entity.}

\mychart{5}{2}{0}{0}{0}{Question 9: Domain discoverability}{The meta-model generation mechanism was always correctly adapting the latest modifications to the conceptual model.}

\section{Intuitiveness and ease of use}
\mychart{5}{2}{0}{0}{0}{Question 10: Intuitiveness and ease of use}{Overall structure of the entity meta-model was easy to understand and intuitive in its use for referencing and chaining properties of an entity.}

\mychart{0}{1}{5}{0}{1}{Question 11: Intuitiveness and ease of use}{The entity meta-model could be structured in a better way.}

\mychart{5}{2}{0}{0}{0}{Question 12: Intuitiveness and ease of use}{Overall, I am rather satisfied with the experience of utilizing the meta-model generation tool.}
